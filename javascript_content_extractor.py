#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script avansat cu Selenium pentru extragerea conÈ›inutului din taburi JavaScript
BikeStylish foloseÈ™te taburi dinamice care se Ã®ncarcÄƒ cu JS
"""

import json
import time
import re
from datetime import datetime
import logging
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from bs4 import BeautifulSoup

# Configurare logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class JavaScriptContentExtractor:
    def __init__(self, json_file_path):
        self.json_file_path = json_file_path
        self.driver = None
        
        # Categorii deja procesate manual
        self.processed_categories = {
            'accesorii-bicicleta', 'accesorii', 'remorci-transport-copii',
            'roti-ajutatoare', 'scaune-pentru-copii', 'transport-si-depozitare',
            'reflectorizante', 'articole-copii-roti-ajutatoare',
            'parti-ghidoane-si-barend-extensiighidon', 'cricuri-de-mijloc',
            'cosuri-pentru-biciclete'
        }

    def setup_driver(self):
        """ConfigureazÄƒ driver-ul Selenium"""
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')  # RuleazÄƒ Ã®n background
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.implicitly_wait(10)
            logger.info("âœ… Driver Selenium configurat cu succes")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Eroare la configurarea driver-ului: {e}")
            return False

    def close_driver(self):
        """Ãnchide driver-ul"""
        if self.driver:
            self.driver.quit()

    def load_categories(self):
        """ÃncarcÄƒ categoriile din JSON"""
        try:
            with open(self.json_file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Eroare la Ã®ncÄƒrcarea JSON: {e}")
            return None

    def save_categories(self, data):
        """SalveazÄƒ categoriile actualizate"""
        try:
            with open(self.json_file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.error(f"Eroare la salvarea JSON: {e}")
            return False

    def extract_tab_content(self, url, category_id):
        """Extrage conÈ›inut din toate taburile unei pagini"""
        try:
            logger.info(f"ğŸŒ Accesez pagina: {url}")
            self.driver.get(url)
            
            # AÈ™teaptÄƒ ca pagina sÄƒ se Ã®ncarce
            WebDriverWait(self.driver, 15).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            # GÄƒseÈ™te toate taburile
            tab_content = {
                'main_content': '',
                'tabs_content': {},
                'all_text_content': '',
                'extracted_sections': {}
            }
            
            # Extrage conÈ›inutul principal fÄƒrÄƒ taburi
            main_soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            tab_content['main_content'] = main_soup.get_text()
            
            # CautÄƒ taburi (diferite selectori posibili)
            tab_selectors = [
                '.tabs .tab',
                '.tab-navigation .tab',
                '.nav-tabs .nav-item',
                '[role="tab"]',
                '.tab-button',
                '.tab-link',
                'a[data-tab]',
                'button[data-tab]'
            ]
            
            tabs_found = []
            for selector in tab_selectors:
                try:
                    tabs = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if tabs:
                        tabs_found = tabs
                        logger.info(f"ğŸ“‹ GÄƒsite {len(tabs)} taburi cu selectorul: {selector}")
                        break
                except:
                    continue
            
            if not tabs_found:
                # ÃncearcÄƒ sÄƒ gÄƒseascÄƒ prin text
                try:
                    common_tab_texts = ['Descriere', 'SpecificaÈ›ii', 'Ghid alegere', 'FAQ', 'Instalare', 'Caracteristici', 'Detalii']
                    for text in common_tab_texts:
                        elements = self.driver.find_elements(By.XPATH, f"//*[contains(text(), '{text}')]")
                        for elem in elements:
                            if elem.tag_name in ['a', 'button', 'div'] and elem.is_displayed():
                                tabs_found.append(elem)
                    
                    if tabs_found:
                        logger.info(f"ğŸ“‹ GÄƒsite {len(tabs_found)} taburi prin text")
                except:
                    pass
            
            # DacÄƒ nu gÄƒseÈ™te taburi, extrage tot conÈ›inutul disponibil
            if not tabs_found:
                logger.info("âš ï¸ Nu s-au gÄƒsit taburi, extrag conÈ›inutul complet al paginii")
                tab_content['all_text_content'] = main_soup.get_text()
                tab_content['extracted_sections'] = self._extract_sections_from_html(main_soup)
            else:
                # ProceseazÄƒ fiecare tab
                for i, tab in enumerate(tabs_found[:8]):  # Maxim 8 taburi
                    try:
                        tab_name = f"tab_{i+1}"
                        
                        # ÃncearcÄƒ sÄƒ obÈ›inÄƒ numele tabului
                        try:
                            tab_text = tab.text.strip()
                            if tab_text:
                                tab_name = tab_text[:30]
                        except:
                            pass
                        
                        logger.info(f"ğŸ” Procesez tabul: {tab_name}")
                        
                        # Click pe tab
                        self.driver.execute_script("arguments[0].scrollIntoView();", tab)
                        time.sleep(1)
                        self.driver.execute_script("arguments[0].click();", tab)
                        time.sleep(2)  # AÈ™teaptÄƒ ca conÈ›inutul sÄƒ se Ã®ncarce
                        
                        # Extrage conÈ›inutul dupÄƒ click
                        updated_soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                        tab_content['tabs_content'][tab_name] = {
                            'html_content': str(updated_soup),
                            'text_content': updated_soup.get_text(),
                            'extracted_data': self._extract_sections_from_html(updated_soup)
                        }
                        
                        logger.info(f"âœ… ConÈ›inut extras din tabul: {tab_name}")
                        
                    except Exception as e:
                        logger.warning(f"âš ï¸ Eroare la procesarea tabului {i+1}: {e}")
                        continue
            
            # Extrage informaÈ›ii finale
            final_content = self._compile_final_content(tab_content)
            
            return final_content
            
        except Exception as e:
            logger.error(f"âŒ Eroare la extragerea conÈ›inutului pentru {category_id}: {e}")
            return None

    def _extract_sections_from_html(self, soup):
        """Extrage secÈ›iuni specifice din HTML"""
        sections = {
            'faqs': [],
            'specifications': {},
            'guides': [],
            'features': [],
            'installation': [],
            'descriptions': []
        }
        
        # FAQ-uri
        faq_elements = soup.find_all(text=re.compile(r'[Cc]e |[Cc]um |[Cc]are |[Dd]e ce |\?'))
        for faq in faq_elements:
            faq_text = faq.strip()
            if len(faq_text) > 20 and '?' in faq_text:
                # GÄƒseÈ™te rÄƒspunsul
                parent = faq.parent if hasattr(faq, 'parent') else None
                if parent:
                    next_elem = parent.find_next_sibling()
                    if next_elem:
                        answer = next_elem.get_text().strip()[:300]
                        sections['faqs'].append({
                            'question': faq_text,
                            'answer': answer
                        })
                        if len(sections['faqs']) >= 8:
                            break
        
        # SpecificaÈ›ii (tabele, liste)
        tables = soup.find_all('table')
        for table in tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 2:
                    key = cells[0].get_text().strip()
                    value = cells[1].get_text().strip()
                    if key and value:
                        sections['specifications'][key] = value
        
        # Caracteristici (liste cu bullet points)
        lists = soup.find_all(['ul', 'ol'])
        for lst in lists:
            items = lst.find_all('li')
            for item in items:
                text = item.get_text().strip()
                if len(text) > 15:
                    sections['features'].append(text[:200])
                    if len(sections['features']) >= 15:
                        break
        
        # Ghiduri È™i descrieri
        headings = soup.find_all(['h2', 'h3'], string=re.compile(r'ghid|alegere|cum sÄƒ|descriere|instalare', re.IGNORECASE))
        for heading in headings:
            content = []
            current = heading.find_next_sibling()
            while current and len(content) < 5:
                if current.name in ['p', 'div']:
                    text = current.get_text().strip()
                    if len(text) > 30:
                        content.append(text[:300])
                current = current.find_next_sibling() if current else None
            
            if content:
                if 'ghid' in heading.get_text().lower() or 'alegere' in heading.get_text().lower():
                    sections['guides'].extend(content)
                elif 'instalare' in heading.get_text().lower():
                    sections['installation'].extend(content)
                else:
                    sections['descriptions'].extend(content)
        
        return sections

    def _compile_final_content(self, tab_content):
        """CompileazÄƒ conÈ›inutul final din toate taburile"""
        compiled = {
            'extraction_timestamp': datetime.now().isoformat(),
            'tabs_processed': len(tab_content.get('tabs_content', {})),
            'comprehensive_faqs': [],
            'detailed_specifications': {},
            'buying_guides': [],
            'installation_guides': [],
            'product_features': [],
            'technical_descriptions': [],
            'all_sections': {}
        }
        
        # CombinÄƒ conÈ›inutul din toate taburile
        all_sections = {}
        
        # ProceseazÄƒ conÈ›inutul principal
        if tab_content.get('extracted_sections'):
            all_sections['main'] = tab_content['extracted_sections']
        
        # ProceseazÄƒ conÈ›inutul din taburi
        for tab_name, tab_data in tab_content.get('tabs_content', {}).items():
            all_sections[tab_name] = tab_data.get('extracted_data', {})
        
        # CombinÄƒ FAQ-urile din toate taburile
        for section_name, section_data in all_sections.items():
            if 'faqs' in section_data:
                compiled['comprehensive_faqs'].extend(section_data['faqs'])
            if 'specifications' in section_data:
                compiled['detailed_specifications'].update(section_data['specifications'])
            if 'guides' in section_data:
                compiled['buying_guides'].extend(section_data['guides'])
            if 'installation' in section_data:
                compiled['installation_guides'].extend(section_data['installation'])
            if 'features' in section_data:
                compiled['product_features'].extend(section_data['features'])
            if 'descriptions' in section_data:
                compiled['technical_descriptions'].extend(section_data['descriptions'])
        
        # DeduplicÄƒ È™i limiteazÄƒ
        compiled['comprehensive_faqs'] = compiled['comprehensive_faqs'][:10]
        compiled['detailed_specifications'] = dict(list(compiled['detailed_specifications'].items())[:20])
        compiled['buying_guides'] = list(set(compiled['buying_guides']))[:8]
        compiled['installation_guides'] = list(set(compiled['installation_guides']))[:6]
        compiled['product_features'] = list(set(compiled['product_features']))[:15]
        compiled['technical_descriptions'] = list(set(compiled['technical_descriptions']))[:10]
        
        compiled['all_sections'] = all_sections
        
        return compiled

    def test_single_category(self, category_id="ghidoline"):
        """TesteazÄƒ extragerea pentru o singurÄƒ categorie"""
        if not self.setup_driver():
            return
        
        try:
            data = self.load_categories()
            if not data:
                return
            
            # GÄƒseÈ™te categoria de test
            test_category = None
            for cat in data.get('categories', []):
                if cat.get('id') == category_id:
                    test_category = cat
                    break
            
            if not test_category:
                logger.error(f"âŒ Nu s-a gÄƒsit categoria {category_id}")
                return
            
            url = test_category.get('url', '')
            logger.info(f"ğŸ§ª Testez categoria: {category_id}")
            logger.info(f"ğŸ“ URL: {url}")
            
            # Extrage conÈ›inutul
            extracted_content = self.extract_tab_content(url, category_id)
            
            if extracted_content:
                logger.info(f"\nğŸ“Š REZULTATE EXTRAGERE JAVASCRIPT:")
                logger.info(f"ğŸ“‹ Taburi procesate: {extracted_content['tabs_processed']}")
                logger.info(f"â“ FAQ-uri gÄƒsite: {len(extracted_content['comprehensive_faqs'])}")
                logger.info(f"ğŸ”§ SpecificaÈ›ii: {len(extracted_content['detailed_specifications'])}")
                logger.info(f"ğŸ“– Ghiduri: {len(extracted_content['buying_guides'])}")
                logger.info(f"âš™ï¸ Instalare: {len(extracted_content['installation_guides'])}")
                logger.info(f"âœ¨ Caracteristici: {len(extracted_content['product_features'])}")
                
                # AfiÈ™eazÄƒ exemple
                if extracted_content['comprehensive_faqs']:
                    logger.info(f"\nğŸ“‹ EXEMPLE FAQ-URI DIN TABURI:")
                    for i, faq in enumerate(extracted_content['comprehensive_faqs'][:3], 1):
                        logger.info(f"   {i}. Q: {faq.get('question', '')[:100]}")
                        logger.info(f"      A: {faq.get('answer', '')[:100]}")
                
                if extracted_content['detailed_specifications']:
                    logger.info(f"\nğŸ”§ EXEMPLE SPECIFICAÈšII:")
                    for key, value in list(extracted_content['detailed_specifications'].items())[:3]:
                        logger.info(f"   {key}: {value}")
                
                # SalveazÄƒ Ã®n JSON
                if 'content_structure' not in test_category:
                    test_category['content_structure'] = {}
                
                test_category['content_structure']['javascript_extracted_content'] = extracted_content
                
                self.save_categories(data)
                logger.info(f"\nâœ… ConÈ›inut JavaScript salvat pentru categoria {category_id}!")
            
        finally:
            self.close_driver()

    def process_all_categories_with_js(self):
        """ProceseazÄƒ toate categoriile cu JavaScript"""
        if not self.setup_driver():
            return
        
        try:
            data = self.load_categories()
            if not data:
                return
            
            categories = data.get('categories', [])
            categories_to_process = [
                cat for cat in categories 
                if cat.get('id') not in self.processed_categories
            ]
            
            logger.info(f"ğŸš€ Ãncepe extragerea JavaScript pentru {len(categories_to_process)} categorii")
            
            processed_count = 0
            for i, category in enumerate(categories_to_process, 1):
                category_id = category.get('id', 'unknown')
                url = category.get('url', '')
                
                if not url:
                    logger.warning(f"âš ï¸ URL lipsÄƒ pentru {category_id}")
                    continue
                
                logger.info(f"\nğŸ“‹ Procesez categoria {i}/{len(categories_to_process)}: {category_id}")
                
                extracted_content = self.extract_tab_content(url, category_id)
                
                if extracted_content:
                    if 'content_structure' not in category:
                        category['content_structure'] = {}
                    
                    category['content_structure']['javascript_extracted_content'] = extracted_content
                    processed_count += 1
                    
                    logger.info(f"âœ… JavaScript content extras pentru {category_id}")
                    
                    # SalveazÄƒ progresul
                    if processed_count % 3 == 0:
                        self.save_categories(data)
                        logger.info(f"ğŸ’¾ Progres salvat: {processed_count}/{len(categories_to_process)}")
                
                time.sleep(3)  # PauzÄƒ Ã®ntre procesÄƒri
            
            # SalveazÄƒ final
            self.save_categories(data)
            logger.info(f"\nğŸ‰ FINALIZAT! Procesate {processed_count} categorii cu conÈ›inut JavaScript!")
            
        finally:
            self.close_driver()

if __name__ == "__main__":
    extractor = JavaScriptContentExtractor(
        r"c:\Users\Maia\Downloads\python\endpoint\bikestylish-catalog\data\categories_ai_enhanced.json"
    )
    
    # TesteazÄƒ pentru o categorie
    print("ğŸ§ª Rulez test pentru o categorie...")
    extractor.test_single_category("ghidoline")
